# Java 8, 9, 10 Study
- References) Modern Java in Action (by RAOUL-GABRIEL URMA, MARIO FUSCO, ALAN MYCROFT) 을 읽고 정리
- 참고한 책과 내용이 다를 수 있음
- 소스코드 참고 : http://www.hanbit.co.kr/src/10202

</br></br>

### 병렬 데이터 처리

</br>

#### 병렬 스트림 parallelStream

- 숫자 n을 인수로 받아서 1부터 n까지 숫자 합 구하는 예제
    ```java
    public long parallelSum(long n){
        return Stream.iterate(1L, i -> i + 1)
                    .limit(n)
                    .parallel() // 스트림을 병렬 스트림으로 변환
                    .reduce(0L, Long::sum);
    }
    ```

- 순차 스트림에 parallel 메소드를 호출하면 기존의 함수형 리듀싱 연산이 병렬로 처리된다.
    - (반대로 병렬 스트림을 직렬로 바꾸려면 ```sequential()``` 을 호출하면 된다.)

- 병렬 성능 테스트 시 참고) 자바 벤치마크 라이브러리 : 자바 마이크로벤치마크 하니스

-	병렬과 거리가 먼 반복 작업을 사용 했을 때 성능이더 나빠질 수도 있다.
    - (iterate를 사용하여 특정 구간 내 숫자를 생성하면 병렬적으로 구성할 수 없기때문에 성능 떨어짐)

- 더 특화된 메소드 사용
    - ```LongStream.rangeClosed``` 는 기본형 long을 직접 사용하므로 박싱과 언박싱 오버헤드가 사라진다.
    - ```LongStream.rangeClosed``` 는 쉽게 청크로 분할할 수 있는 숫자 범위를 생산한다.
        ```java
        LongStream.rangeClosed(1, N)
            .parallel()
            .reduce(0L, Long::sum)
        ```
     - iterate 대신에 위와 같이 사용했을 때, ```parallel()``` 을 사용하면 더 성능이 좋은 걸 확인할 수 있다.
 
</br>
 
#### 병렬 스트림의 올바른 사용법

- 공유된 상태를 바꾸는 알고리즘 사용하면 안된다. 
    - 다수의 스레드에서 동시에 데이터에 접근하는 데이터 레이스 문제가 일어남.
    - 동기화로 문제를 해결하다보면 병렬화의 특성이 없어짐.
    
- 확신이 서지않으면 직접 측정 - 벤치마크

- 박싱을 주의
    - 되도록이면 기본형 특화 스트림 사용 ```IntStream```, ```LongStream```, ```DoubleStream```

- 순차 스트림보다 병렬 스트림에서 성능이 떨어지는 연산이있다. 
    - 특히 ```limit``` 이나 ```findFirst``` 처럼 요소의 순서에 의존하는 연산을 주의 
    - 예를 들어 ```findAny```는 요소의 순서와 상관없이 연산하므로 ```findFirst``` 보다 성능이 좋다. 
    - 정렬된 스트림에 ```unordered``` 를 호출하면 비정렬된 스트림을 얻을 수 있다.
      스트림에 N개 요소가 있을 때 요소의 순서가 상관 없다면, 비정렬된 스트림에 ```limit```을 호출하는 것이 더 효율적이다.

- 스트림에서 수행하는 전체 파이프라인 연산 비용 고려
	
- 소량의 데이터에서는 병렬 스트림이 도움되지 않는다.

- 스트림을 구성하는 자료구조 확인
    - 예를 들어 ArrayList를 LinkedList 보다 효율적으로 분할 할 수 있다. LinkedList를 분할하려면 모든 요소를 탐색해야하기 때문에..

- 스트림의 특성과 파이프라인의 중간 연산이 스트림의 특성을 어떻게 바꾸는지에 따라 분해 과정의 성능이 달라질수있다. 
    - 예를들어 ```SIZED``` 스트림은 정확히 같은 크기의 두 스트림으로 분할할 수 있으므로 효과적으로 스트림을 병렬 처리 할 수 있지만 
      필터 연산이 있으면 스트림의 길이를 예측할 수 없으므로 효과적으로 스트림을 병렬처리할 수 있을지 알 수 없게 된다.

- 최종 연산의 병합 과정 비용을 살펴보라. 병합과정의 비용이 비싸다면 병렬 스트림으로 얻은 성능의 이익이 서브스트림의 부분 결과를 합치는 과정에서 상쇄될 수 있다.

</br>

#### 분해와 관련해서 다양한 스트림 소스의 병렬화 친밀도 요약 설명

|소스|분해성|
|----|-----|
|ArrayList|훌륭함|
|LinkedList|나쁨|
|IntStream.range|훌륭함|
|Stream.iterate|나쁨|
|HashSet|좋음|
|TreeSet|좋음|

</br>

#### 포크/조인 프레임워크

- 포크/조인 프레임워크는 병렬화할 수 있는 작업을 재귀적으로 작은 작업으로 분할한 다음에 서브태스크 각각의 결과를 합쳐서 전체 결과를 만들도록 설계되었다. 
    포크/조인 프레임워크에서는 서브태스크를 스레드 풀(ForkJoinPool)의 작업자 스레드에 분산 할당하는 ```ExecutorService``` 인터페이스를 구현한다.

- ```RecursiveTask``` 활용
    - 스레드 풀을 이용하려면 ```RecursiveTask<R>``` 의 서브클래스를 만들어야 한다. ```RecursiveTask``` 를 정의하려면 
        추상 메서드 ```compute``` 를 구현해야 한다.
    - ```protected abstract R compute();```
        - 여기서 R은 병렬화된 태스크가 생성하는 결과 형식 또는 결과가 없을 때는 ```RecursiveAction``` 형식이다.
    - ```RecursiveTask``` 의 ..compute 메소드 생성 과정 생략
    - ```ForkJoinTask``` 를 만들어서 생성한 태스크를 새로운 ```ForkJoinPool```의 invoke 메소드로 전달
    - ```ForkJoinTask```에서 실행되는 마지막 invoke 메서드의 반환 값은 사용자가 정의한 태스크이 결과가 된다.

- 포크/조인 프레임워크를 제대로 사용하는 방법
    - ```join``` 메소드를 태스크에 호출하면 태스크가 생산하는 결과가 준비될 때 까지 호출자를 블록 시킨다. 
        따라서 두 서브태스크가 모두 시작된 다음에 ```join```을 호출해야한다. 그렇지 않으면 각각의 서브태스크가 다른 태스크가 끝나길 기다리는 일이 발생한다.
    - 서브태스크에 ```fork``` 메소드를 호출해서 ```ForkJoinPool```의 일정을 조절 할 수있다. 
        왼쪽 작업과 오른쪽 작업 모두에 ```fork``` 메소드를 호출하는 것이 자연스러울 것 같지만 
        한 쪽 작업에는 ```fork```를 호출하는 것보다는 ```compute```를 호출하는 것이 효율적이다. 
        그러면 두 서브태스크의 한 태스크에는 같은 스레드를 재사용 할 수 있으므로 풀에서 불필요한 태스크를 할당하는 오버헤드를 피할 수 있다.
    - 포크/조인 프레임워크를 이용하는 병렬 계산은 디버깅하기 어렵다. (스택 트레이스 도움 안됨)
    - 멀티코어에 포크/조인 프레임워크를 사용하는 것이 순차 처리보다 무조건 빠른 것이 아니다. 고려할 사항이 많음.

- 작업 훔치기
    - 병렬로 작업을 수행할때 나눠진 각각의 태스크는 무조건 같은 시간에 종료된다고 보장할 수 없다. 
    
    - 포크/조인 프레임워크에서는 작업 훔치기라는 기법으로 이 문제를 해결한다. 
      - 해당 기법에서는 ```ForkJoinPool```의 모든 스레드를 거의 공정하게 분할한다. 
      - 각각의 스레드는 자신에게 할당된 태스크를 포함하는 이중 연결 리스트 를 참조하면서 작업이 끝날 때 마다 
        큐의 헤드에서 다른 태스크를 가져와서 작업을 처리한다. 
      - 다른 스레드보다 먼저 작업을 처리한 스레드는 유휴 상태로 바뀌는 것이 아니라 다른 스레드의 꼬리에서 작업을 훔쳐온다. 
      - 모든 태스크가 작업을 끝낼 때 까지, 즉 모든 큐가 빌 때까지 이 과정을 반복한다. 
      - 따라서 태스크의 크기를 작게 나누어야 작업자 스레드 간의 작업부하를 비슷한 수준으로 유지할 수 있다.


</br>


</br>


</br>


</br>


</br>
